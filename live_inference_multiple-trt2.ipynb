{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Live Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check connected video device address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "from jetcam.usb_camera import USBCamera\n",
    "\n",
    "# USB Camera\n",
    "camera1 = USBCamera(width=224, height=224, capture_device=1) # confirm the capture_device number\n",
    "#camera = USBCamera(width=244, height=244, capture_width=640, capture_height=480, capture_de)\n",
    "\n",
    "# CSI Camera (Raspberry Pi Camera Module V2)\n",
    "camera = CSICamera(width=224, height=224, capture_device=0)\n",
    "#camera1 = CSICamera(width=244, height=244, capture_device=1)\n",
    "\n",
    "camera.running = True\n",
    "camera1.running = True\n",
    "print(\"camera created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "image_widget2 = ipywidgets.Image(format='jpeg')\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "camera_link2 = traitlets.dlink((camera1, 'value'), (image_widget2, 'value'), transform=bgr8_to_jpeg)\n",
    "#display(image_widget)\n",
    "#display(image_widget2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment/edit the associated lines for the classification task you're building and execute the cell.\n",
    "This cell should only take a few seconds to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('/nvdli-nano/data/classification/my_model_trt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live  Execution\n",
    "Execute the cell below to set up the live execution widget.  This cell should only take a few seconds to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from utils import preprocess\n",
    "import torch.nn.functional as F\n",
    "\n",
    "CATEGORIES = ['background', 'bluecar', 'yellowcar']\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "state_widget1 = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "prediction_widget = ipywidgets.Text(description='prediction')\n",
    "prediction_widget1 = ipywidgets.Text(description='prediction')\n",
    "score_widgets = []\n",
    "score_widgets1 = []\n",
    "for category in CATEGORIES:\n",
    "    score_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, description=category, orientation='vertical')\n",
    "    score_widget1 = ipywidgets.FloatSlider(min=0.0, max=1.0, description=category, orientation='vertical')\n",
    "    score_widgets.append(score_widget)\n",
    "    score_widgets1.append(score_widget1)\n",
    "\n",
    "def live(state_widget, model_trt, camera, prediction_widget, score_widget):\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = model_trt(preprocessed)\n",
    "        output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "        category_index = output.argmax()\n",
    "        prediction_widget.value = CATEGORIES[category_index]\n",
    "        for i, score in enumerate(list(output)):\n",
    "            score_widgets[i].value = score  \n",
    "\n",
    "def live1(state_widget1, model_trt, camera1, prediction_widget1, score_widget1):\n",
    "    while state_widget1.value == 'live':\n",
    "        image1 = camera1.value\n",
    "        preprocessed1 = preprocess(image1)\n",
    "        output1 = model_trt(preprocessed1)\n",
    "        output1 = F.softmax(output1, dim=1).detach().cpu().numpy().flatten()\n",
    "        category_index1 = output1.argmax()\n",
    "        prediction_widget1.value = CATEGORIES[category_index1]\n",
    "        for i, score1 in enumerate(list(output1)):\n",
    "            score_widgets1[i].value = score1 \n",
    "\n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model_trt, camera, prediction_widget, score_widget))\n",
    "        execute_thread.start()\n",
    "        \n",
    "def start_live1(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live1, args=(state_widget1, model_trt, camera1, prediction_widget1, score_widget1))\n",
    "        execute_thread.start() \n",
    "        \n",
    "state_widget.observe(start_live, names='value')\n",
    "state_widget1.observe(start_live1, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox(score_widgets),\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "live_execution_widget1 = ipywidgets.VBox([\n",
    "    ipywidgets.HBox(score_widgets1),\n",
    "    prediction_widget1,\n",
    "    state_widget1\n",
    "])\n",
    "\n",
    "print(\"live_execution_widget created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Interactive Tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_camera = ipywidgets.HBox([image_widget, live_execution_widget])\n",
    "second_camera = ipywidgets.HBox([image_widget2, live_execution_widget1])\n",
    "\n",
    "print(\"Drive-thru camera 1\")\n",
    "display(first_camera)\n",
    "print(\"Drive-thru camera 2\")\n",
    "display(second_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.running = False\n",
    "#camera.cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbot-labs",
   "language": "python",
   "name": "jetbot-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
